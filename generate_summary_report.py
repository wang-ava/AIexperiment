"""
ç”Ÿæˆæ‰€æœ‰æ¨¡å‹çš„æ€»ç»“æŠ¥å‘Š
å¯¹æ¯”åˆ†ææ‰€æœ‰æ·±åº¦å­¦ä¹ æ–¹æ³•çš„æ€§èƒ½
"""
import os
import glob
from datetime import datetime
import re


def parse_report_file(filepath):
    """
    è§£æå•ä¸ªæŠ¥å‘Šæ–‡ä»¶ï¼Œæå–å…³é”®ä¿¡æ¯
    """
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æå–æ¨¡å‹åç§°
        model_name_match = re.search(r'ã€(.+?)ã€‘è®­ç»ƒæŠ¥å‘Š', content)
        if not model_name_match:
            model_name_match = re.search(r'\s+(.+?)\s+è®­ç»ƒæŠ¥å‘Š', content)
        model_name = model_name_match.group(1).strip() if model_name_match else "æœªçŸ¥æ¨¡å‹"
        
        # æå–æµ‹è¯•å‡†ç¡®ç‡
        test_acc_match = re.search(r'æµ‹è¯•å‡†ç¡®ç‡:\s*([\d.]+)', content)
        test_acc = float(test_acc_match.group(1)) if test_acc_match else 0.0
        
        # æå–è®­ç»ƒå‡†ç¡®ç‡
        train_acc_match = re.search(r'è®­ç»ƒå‡†ç¡®ç‡.*?:\s*([\d.]+)', content)
        train_acc = float(train_acc_match.group(1)) if train_acc_match else 0.0
        
        # æå–è®­ç»ƒæ—¶é—´
        time_match = re.search(r'è®­ç»ƒæ—¶é—´:\s*([\d.]+)\s*ç§’', content)
        training_time = float(time_match.group(1)) if time_match else 0.0
        
        # æå–ç½‘ç»œç»“æ„
        structure_match = re.search(r'ç½‘ç»œç»“æ„:\s*(.+?)(?:\n|$)', content)
        structure = structure_match.group(1).strip() if structure_match else "æœªçŸ¥"
        
        # æå–è®­ç»ƒè½®æ•°
        epochs_match = re.search(r'è®­ç»ƒè½®æ•°:\s*(\d+)', content)
        epochs = int(epochs_match.group(1)) if epochs_match else 0
        
        # æå–å­¦ä¹ ç‡
        lr_match = re.search(r'å­¦ä¹ ç‡:\s*([\d.]+)', content)
        learning_rate = float(lr_match.group(1)) if lr_match else 0.0
        
        # æå–æ–‡ä»¶ä¿®æ”¹æ—¶é—´ä½œä¸ºè®­ç»ƒæ—¶é—´
        file_time = datetime.fromtimestamp(os.path.getmtime(filepath))
        
        return {
            'model_name': model_name,
            'test_acc': test_acc,
            'train_acc': train_acc,
            'training_time': training_time,
            'structure': structure,
            'epochs': epochs,
            'learning_rate': learning_rate,
            'file_time': file_time,
            'filepath': filepath
        }
    except Exception as e:
        print(f"è­¦å‘Š: è§£ææ–‡ä»¶ {filepath} æ—¶å‡ºé”™: {e}")
        return None


def generate_summary_report(reports_dir='reports'):
    """
    ç”Ÿæˆæ‰€æœ‰æ¨¡å‹çš„æ€»ç»“æŠ¥å‘Š
    """
    # æŸ¥æ‰¾æ‰€æœ‰æŠ¥å‘Šæ–‡ä»¶
    report_files = glob.glob(os.path.join(reports_dir, '*.txt'))
    
    if not report_files:
        print(f"é”™è¯¯: åœ¨ {reports_dir} ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°æŠ¥å‘Šæ–‡ä»¶")
        return
    
    print(f"æ‰¾åˆ° {len(report_files)} ä¸ªæŠ¥å‘Šæ–‡ä»¶")
    
    # è§£ææ‰€æœ‰æŠ¥å‘Š
    models_data = []
    for filepath in report_files:
        data = parse_report_file(filepath)
        if data:
            models_data.append(data)
    
    if not models_data:
        print("é”™è¯¯: æ²¡æœ‰æˆåŠŸè§£æä»»ä½•æŠ¥å‘Š")
        return
    
    # æŒ‰æµ‹è¯•å‡†ç¡®ç‡æ’åº
    models_data.sort(key=lambda x: x['test_acc'], reverse=True)
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    report_lines = []
    
    def add_line(text):
        print(text)
        report_lines.append(text)
    
    add_line("=" * 80)
    add_line(" " * 25 + "Fashion-MNIST æ·±åº¦å­¦ä¹ æ¨¡å‹æ€»ç»“æŠ¥å‘Š")
    add_line("=" * 80)
    
    add_line(f"\nç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    add_line(f"åˆ†æçš„æ¨¡å‹æ•°é‡: {len(models_data)}")
    
    # 1. æ¨¡å‹æ€§èƒ½å¯¹æ¯”è¡¨
    add_line("\n" + "=" * 80)
    add_line("ã€ä¸€ã€æ¨¡å‹æ€§èƒ½å¯¹æ¯”ã€‘")
    add_line("=" * 80)
    
    add_line("\næ’å | æ¨¡å‹åç§° | æµ‹è¯•å‡†ç¡®ç‡ | è®­ç»ƒå‡†ç¡®ç‡ | è®­ç»ƒæ—¶é—´(ç§’)")
    add_line("-" * 80)
    
    for i, model in enumerate(models_data, 1):
        add_line(f"{i:2d}   | {model['model_name']:30s} | {model['test_acc']:6.2%}     | "
                f"{model['train_acc']:6.2%}     | {model['training_time']:8.2f}")
    
    # 2. æœ€ä½³æ¨¡å‹åˆ†æ
    add_line("\n" + "=" * 80)
    add_line("ã€äºŒã€æœ€ä½³æ¨¡å‹åˆ†æã€‘")
    add_line("=" * 80)
    
    best_model = models_data[0]
    add_line(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model['model_name']}")
    add_line(f"   æµ‹è¯•å‡†ç¡®ç‡: {best_model['test_acc']:.4f} ({best_model['test_acc']:.2%})")
    add_line(f"   è®­ç»ƒå‡†ç¡®ç‡: {best_model['train_acc']:.4f} ({best_model['train_acc']:.2%})")
    add_line(f"   è®­ç»ƒæ—¶é—´: {best_model['training_time']:.2f} ç§’ ({best_model['training_time']/60:.2f} åˆ†é’Ÿ)")
    add_line(f"   ç½‘ç»œç»“æ„: {best_model['structure']}")
    add_line(f"   å­¦ä¹ ç‡: {best_model['learning_rate']}")
    add_line(f"   è®­ç»ƒè½®æ•°: {best_model['epochs']}")
    
    # 3. å„ç±»åˆ«æœ€ä¼˜æ¨¡å‹
    add_line("\n" + "=" * 80)
    add_line("ã€ä¸‰ã€å„ç±»åˆ«æœ€ä¼˜æ¨¡å‹ã€‘")
    add_line("=" * 80)
    
    # æœ€å¿«è®­ç»ƒé€Ÿåº¦
    fastest_model = min(models_data, key=lambda x: x['training_time'])
    add_line(f"\nâš¡ æœ€å¿«è®­ç»ƒé€Ÿåº¦: {fastest_model['model_name']}")
    add_line(f"   è®­ç»ƒæ—¶é—´: {fastest_model['training_time']:.2f} ç§’")
    add_line(f"   æµ‹è¯•å‡†ç¡®ç‡: {fastest_model['test_acc']:.2%}")
    
    # æœ€é«˜å‡†ç¡®ç‡
    add_line(f"\nğŸ¯ æœ€é«˜å‡†ç¡®ç‡: {best_model['model_name']}")
    add_line(f"   æµ‹è¯•å‡†ç¡®ç‡: {best_model['test_acc']:.2%}")
    
    # æœ€ä½³æ€§ä»·æ¯” (å‡†ç¡®ç‡/æ—¶é—´)
    efficiency = [(m['test_acc'] / (m['training_time'] / 60), m) for m in models_data if m['training_time'] > 0]
    if efficiency:
        best_efficiency = max(efficiency, key=lambda x: x[0])
        eff_score, eff_model = best_efficiency
        add_line(f"\nğŸ’ æœ€ä½³æ€§ä»·æ¯”: {eff_model['model_name']}")
        add_line(f"   å‡†ç¡®ç‡: {eff_model['test_acc']:.2%}")
        add_line(f"   è®­ç»ƒæ—¶é—´: {eff_model['training_time']/60:.2f} åˆ†é’Ÿ")
        add_line(f"   æ€§ä»·æ¯”å¾—åˆ†: {eff_score:.4f} (å‡†ç¡®ç‡/åˆ†é’Ÿ)")
    
    # 4. æ–°å¢æ¨¡å‹ä¸åŸºå‡†å¯¹æ¯”
    add_line("\n" + "=" * 80)
    add_line("ã€å››ã€Fashion-MNIST Benchmark å¯¹æ¯”ã€‘")
    add_line("=" * 80)
    
    add_line("\næ ¹æ® GitHub Fashion-MNIST å®˜æ–¹ Benchmark:")
    add_line("  - Wide ResNet-28-10 + Random Erasing: 96.3% (å®˜æ–¹benchmark)")
    add_line("  - DenseNet-BC: 95.4% (å®˜æ–¹benchmark)")
    add_line("  - Capsule Network: 93.6% (å®˜æ–¹benchmark)")
    
    add_line("\næœ¬æ¬¡å®éªŒç»“æœ:")
    for model in models_data:
        if 'Wide' in model['model_name'] or 'WRN' in model['model_name']:
            add_line(f"  - {model['model_name']}: {model['test_acc']:.1%} (æœ¬å®éªŒ)")
        elif 'Dense' in model['model_name']:
            add_line(f"  - {model['model_name']}: {model['test_acc']:.1%} (æœ¬å®éªŒ)")
        elif 'Capsule' in model['model_name'] or 'CapsNet' in model['model_name']:
            add_line(f"  - {model['model_name']}: {model['test_acc']:.1%} (æœ¬å®éªŒ)")
    
    # 5. è¯¦ç»†ç»Ÿè®¡åˆ†æ
    add_line("\n" + "=" * 80)
    add_line("ã€äº”ã€ç»Ÿè®¡åˆ†æã€‘")
    add_line("=" * 80)
    
    test_accs = [m['test_acc'] for m in models_data]
    train_accs = [m['train_acc'] for m in models_data]
    times = [m['training_time'] for m in models_data]
    
    add_line(f"\næµ‹è¯•å‡†ç¡®ç‡ç»Ÿè®¡:")
    add_line(f"  - å¹³å‡å€¼: {sum(test_accs)/len(test_accs):.2%}")
    add_line(f"  - æœ€é«˜å€¼: {max(test_accs):.2%}")
    add_line(f"  - æœ€ä½å€¼: {min(test_accs):.2%}")
    add_line(f"  - æ ‡å‡†å·®: {(sum([(x-sum(test_accs)/len(test_accs))**2 for x in test_accs])/len(test_accs))**0.5:.4f}")
    
    add_line(f"\nè®­ç»ƒæ—¶é—´ç»Ÿè®¡:")
    add_line(f"  - å¹³å‡å€¼: {sum(times)/len(times):.2f} ç§’ ({sum(times)/len(times)/60:.2f} åˆ†é’Ÿ)")
    add_line(f"  - æœ€å¿«: {min(times):.2f} ç§’")
    add_line(f"  - æœ€æ…¢: {max(times):.2f} ç§’")
    
    # 6. æ¨¡å‹æ¶æ„å¯¹æ¯”
    add_line("\n" + "=" * 80)
    add_line("ã€å…­ã€æ¨¡å‹æ¶æ„ç‰¹ç‚¹ã€‘")
    add_line("=" * 80)
    
    architecture_analysis = {
        'Wide ResNet': 'å¢åŠ ç½‘ç»œå®½åº¦è€Œéæ·±åº¦ï¼Œä½¿ç”¨Random Erasingæ•°æ®å¢å¼ºï¼Œé€‚åˆå¤æ‚å›¾åƒåˆ†ç±»',
        'DenseNet': 'Denseè¿æ¥ä¿ƒè¿›ç‰¹å¾é‡ç”¨ï¼Œå‡å°‘æ¢¯åº¦æ¶ˆå¤±ï¼Œå‚æ•°æ•ˆç‡é«˜',
        'Capsule': 'ä½¿ç”¨å‘é‡è¡¨ç¤ºç‰¹å¾ï¼ŒåŠ¨æ€è·¯ç”±ç®—æ³•ï¼Œæ›´å¥½ä¿ç•™ç©ºé—´å±‚æ¬¡å…³ç³»',
        'ResNet': 'æ®‹å·®è¿æ¥è§£å†³æ¢¯åº¦æ¶ˆå¤±ï¼Œå¯ä»¥è®­ç»ƒå¾ˆæ·±çš„ç½‘ç»œ',
        'LeNet': 'ç»å…¸CNNæ¶æ„ï¼Œç»“æ„ç®€å•ï¼Œè®­ç»ƒå¿«é€Ÿ',
        'MLP': 'å…¨è¿æ¥ç½‘ç»œï¼ŒåŸºå‡†æ¨¡å‹',
        'CNN': 'æ ‡å‡†å·ç§¯ç¥ç»ç½‘ç»œ'
    }
    
    for model in models_data:
        model_type = None
        for key in architecture_analysis.keys():
            if key in model['model_name']:
                model_type = key
                break
        
        if model_type:
            add_line(f"\n{model['model_name']}:")
            add_line(f"  ç‰¹ç‚¹: {architecture_analysis[model_type]}")
            add_line(f"  æ€§èƒ½: æµ‹è¯•å‡†ç¡®ç‡ {model['test_acc']:.2%}, è®­ç»ƒæ—¶é—´ {model['training_time']/60:.2f} åˆ†é’Ÿ")
    
    # 7. ç»“è®ºä¸å»ºè®®
    add_line("\n" + "=" * 80)
    add_line("ã€ä¸ƒã€ç»“è®ºä¸å»ºè®®ã€‘")
    add_line("=" * 80)
    
    add_line("\nğŸ“Š å®éªŒç»“è®º:")
    add_line(f"  1. åœ¨æœ¬æ¬¡å®éªŒä¸­ï¼Œ{best_model['model_name']} å–å¾—äº†æœ€ä½³æ€§èƒ½")
    add_line(f"  2. æ‰€æœ‰æ¨¡å‹çš„å¹³å‡æµ‹è¯•å‡†ç¡®ç‡ä¸º {sum(test_accs)/len(test_accs):.2%}")
    add_line(f"  3. è®­ç»ƒæ—¶é—´èŒƒå›´ä» {min(times):.2f} ç§’åˆ° {max(times):.2f} ç§’")
    
    add_line("\nğŸ’¡ åº”ç”¨å»ºè®®:")
    add_line("  - è¿½æ±‚æœ€é«˜å‡†ç¡®ç‡: æ¨èä½¿ç”¨ Wide ResNet æˆ– DenseNet")
    add_line("  - å¿«é€ŸåŸå‹å¼€å‘: æ¨èä½¿ç”¨ LeNet æˆ–æ ‡å‡†CNN")
    add_line("  - èµ„æºå—é™ç¯å¢ƒ: æ¨èä½¿ç”¨ MLP æˆ–ç®€åŒ–ç‰ˆCNN")
    add_line("  - ç ”ç©¶ç›®çš„: æ¨èå°è¯• Capsule Network ç­‰æ–°é¢–æ¶æ„")
    
    add_line("\nğŸ”¬ è¿›ä¸€æ­¥ä¼˜åŒ–æ–¹å‘:")
    add_line("  1. æ•°æ®å¢å¼º: ä½¿ç”¨æ›´å¤šå¢å¼ºæŠ€æœ¯(Random Erasing, Cutout, Mixup)")
    add_line("  2. æ­£åˆ™åŒ–: è°ƒæ•´Dropoutæ¯”ç‡ï¼Œä½¿ç”¨L2æ­£åˆ™åŒ–")
    add_line("  3. å­¦ä¹ ç‡ç­–ç•¥: ä½¿ç”¨å­¦ä¹ ç‡è¡°å‡ã€warmupç­‰æŠ€æœ¯")
    add_line("  4. æ¨¡å‹é›†æˆ: ç»“åˆå¤šä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœ")
    add_line("  5. è¶…å‚æ•°ä¼˜åŒ–: ä½¿ç”¨ç½‘æ ¼æœç´¢æˆ–è´å¶æ–¯ä¼˜åŒ–")
    
    # 8. å‚è€ƒæ–‡çŒ®
    add_line("\n" + "=" * 80)
    add_line("ã€å…«ã€å‚è€ƒæ–‡çŒ®ã€‘")
    add_line("=" * 80)
    
    add_line("\n1. Fashion-MNISTå®˜æ–¹ä»“åº“:")
    add_line("   https://github.com/zalandoresearch/fashion-mnist")
    
    add_line("\n2. ç›¸å…³è®ºæ–‡:")
    add_line("   - Wide Residual Networks (Zagoruyko & Komodakis, 2016)")
    add_line("   - Densely Connected Convolutional Networks (Huang et al., 2017)")
    add_line("   - Dynamic Routing Between Capsules (Sabour et al., 2017)")
    add_line("   - Deep Residual Learning (He et al., 2015)")
    add_line("   - Random Erasing Data Augmentation (Zhong et al., 2017)")
    
    add_line("\n" + "=" * 80)
    add_line("æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
    add_line("=" * 80)
    
    # ä¿å­˜æŠ¥å‘Š
    output_filename = f"æ€»ç»“æŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    output_path = os.path.join(reports_dir, output_filename)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(report_lines))
    
    print(f"\nâœ“ æ€»ç»“æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
    
    return output_path


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("ç”ŸæˆFashion-MNISTæ·±åº¦å­¦ä¹ æ¨¡å‹æ€»ç»“æŠ¥å‘Š")
    print("=" * 70)
    
    # ç¡®å®šæŠ¥å‘Šç›®å½•
    reports_dir = 'reports'
    if not os.path.exists(reports_dir):
        print(f"é”™è¯¯: æŠ¥å‘Šç›®å½• {reports_dir} ä¸å­˜åœ¨")
        print("è¯·å…ˆè¿è¡Œå„ä¸ªæ¨¡å‹è®­ç»ƒè„šæœ¬ç”ŸæˆæŠ¥å‘Š")
        return
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    output_path = generate_summary_report(reports_dir)
    
    if output_path:
        print(f"\nâœ“ æˆåŠŸç”Ÿæˆæ€»ç»“æŠ¥å‘Š")
        print(f"âœ“ æŠ¥å‘Šä½ç½®: {output_path}")


if __name__ == '__main__':
    main()

